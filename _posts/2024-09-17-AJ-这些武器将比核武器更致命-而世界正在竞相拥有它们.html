---
layout: post
title: 这些武器将比核武器更致命，而世界正在竞相拥有它们
date: 2024-09-17 19:36:01.000000000 +08:00
link: https://chinese.aljazeera.net/news/political/2024/9/17/%e8%bf%99%e4%ba%9b%e6%ad%a6%e5%99%a8%e5%b0%86%e6%af%94%e6%a0%b8%e6%ad%a6%e5%99%a8%e6%9b%b4%e8%87%b4%e5%91%bd%e8%80%8c%e4%b8%96%e7%95%8c%e6%ad%a3%e5%9c%a8%e7%ab%9e%e7%9b%b8%e6%8b%a5%e6%9c%89
categories: aj
---

<div aria-live="polite" aria-atomic="true"><p>在这篇译自《外交事务》杂志的文章中，作者同时谈到了一个重要而危险的话题，即将构成未来战争一个方面的独立武器。这些武器的危险在于它们完全独立地基于人工智能技术做出瞄准和杀伤的决策，这引发了许多问题，即当我们抛开人的因素时，包括人的复杂的感受和考虑，以及根据现实的变化而产生的政治和利益考虑，让机器成为搜索目标、选择目标、然后瞄准目标的东西，除了提前对武器进行编程之外，无需任何人为干预，那么这些武器能够产生多大程度的破坏。</p>
<p>这些武器将给一个充满冲突和战争的世界带来什么影响？这就是本文想要回答的问题。</p><div><h2>阅读更多<!-- --> </h2><ul><li><a href="https://chinese.aljazeera.net/news/2024/9/17/%e9%9d%9e%e6%b4%b2%e5%9c%a8%e4%b8%ad%e5%9b%bd%e5%86%9b%e4%ba%8b%e7%90%86%e8%ae%ba%e4%b8%ad%e7%9a%84%e5%9c%b0%e4%bd%8d%e5%a6%82%e4%bd%95?traffic_source=KeepReading">非洲在中国军事理论中的地位如何？</a></li><li><a href="https://chinese.aljazeera.net/news/2024/9/17/%e4%bb%a5%e8%89%b2%e5%88%97%e6%80%bb%e7%90%86%e5%86%85%e5%a1%94%e5%b0%bc%e4%ba%9a%e8%83%a1%e5%ae%a3%e5%b8%83%e6%89%a9%e5%a4%a7%e6%88%98%e4%ba%89%e7%9b%ae%e6%a0%87%e8%87%b3%e5%8c%85%e6%8b%ac%e9%bb%8e?traffic_source=KeepReading">以色列总理内塔尼亚胡宣布扩大战争目标至包括黎巴嫩边境</a></li><li><a href="https://chinese.aljazeera.net/opinions/2024/9/17/%e5%8c%97%e7%ba%a6%e4%b9%89%e5%8a%a1%e4%b8%8d%e8%83%bd%e5%87%8c%e9%a9%be%e4%ba%8e%e5%9b%bd%e9%99%85%e6%b3%95%e4%b9%8b%e4%b8%8a?traffic_source=KeepReading">北约义务不能凌驾于国际法之上</a></li><li><a href="https://chinese.aljazeera.net/news/2024/9/17/%e6%99%ae%e4%ba%ac%e8%87%aa%e4%bf%84%e4%b9%8c%e6%88%98%e4%ba%89%e4%bb%a5%e6%9d%a5%e4%b8%8b%e4%bb%a4%e7%ac%ac%e4%b8%89%e6%ac%a1%e5%a2%9e%e5%8a%a0%e4%bf%84%e7%bd%97%e6%96%af%e5%86%9b%e9%98%9f%e4%ba%ba?traffic_source=KeepReading">普京自俄乌战争以来下令第三次增加俄罗斯军队人数</a></li></ul></div>
<p>去年，乌克兰无人机公司Saker声称已开发出一种名为“Saker Scout”的全自动武器，它依靠人工智能自行决定在战场上杀死谁。</p>
<p>该公司负责人宣布无人机发起小规模自主攻击。尽管该公司的说法尚未得到任何独立第三方的证实，但制造这种武器所需的技术确实存在，更不用说使用人工智能技术来设计和操作自主武器可能只是一个小小的技术步骤，但它仍然具有道德和法律层面的意义。</p>
<p>当武器能够自行搜索和选择目标时，就会引发有关此类决定的责任和道德后果的问题。</p>
<p>另一方面，Saker飞机的部署证实，执行自主武器使用法律法规的时间正在离我们越来越远。十年来，各国一直在争论如何处理自主武器，但最终未能达成协议，制定减少此类武器危害的法规。</p>
<p>然而，仍然迫切需要达成国际协议，因为自主武器的无节制发展可能会导致人类无法控制的战争的真正风险，而对士兵和平民的保护也会减少。</p>
<p>即使全面禁止自主武器很难实现，政府也可以采取许多实用的法规来减轻自主武器可能带来的最严重风险。但世界各国无限制地制造自主武器的做法，将使人类滑入后果可怕的深渊，我们将面临奔向机器控制的危险战争未来的危险。</p>
<figure id="attachment_799469" aria-describedby="caption-attachment-799469"><a href="https://youtu.be/ZNUlpXyHS0E"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2024/09/maxresdefault-1726569009.webp?w=770&amp;resize=770%2C433" alt="" data-recalc-dims="1"/></a><figcaption id="caption-attachment-799469"><a href="https://youtu.be/ZNUlpXyHS0E">人工智能对战争的影响</a></figcaption></figure>
<h3>快到了</h3>
<p>自20世纪80年代以来，军队一直在有限的防御环境下使用部分自主武器（即他们不完全依赖人工智能或自主技术来做出决策*）。如今，至少有30个国家正在运行系统来对抗和防御空中和导弹攻击，或压制针对地面车辆的敌方导弹。一旦激活，这些系统可以自动感知来袭导弹、迫击炮或飞机的威胁，并立即进行干预拦截。</p>
<p>但仍然存在人为因素来监督他们的操作并在出现问题时进行干预。然而，问题始终是，军队在采用商业部门已经开发的人工智能技术方面进展缓慢，部分原因是军事部门采购和供应流程涉及漫长而复杂的官僚程序。</p>
<p>但令人有点希望的是，自从俄乌战争爆发以来，事情已经开始发生变化，这场战争加速了双方的创新步伐，尤其是在小型无人机等商业技术领域。</p>
<p>莫斯科和基辅扩大了无人机的使用范围，用于侦察和间谍活动以及对地面部队的攻击，这些用途反过来又导致了新的对抗措施的发展，包括破坏无人机通信链路或定位地面操作员的电子战系统，这样就可以轻松地将他们定为目标。从战略角度来看，专注于无人机控制器似乎是合乎逻辑的，因为大多数这些飞机都被设计为远程控制，这使得人类操作员成为暗杀的主要目标。</p>
<p>没有人为因素，传统无人机就彻底失去价值。这就是自主（自主操作）无人机发挥最大价值的地方，因为后者不依赖于薄弱的通信链路（例如可能受到破坏或干扰的无线电通信或网络），此外，为了对抗它，你必须找到飞机本身并摧毁它。</p>
<figure id="attachment_799459" aria-describedby="caption-attachment-799459"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2024/09/doc-36b33vu-1723116338-1726568986.jpg?w=770&amp;resize=770%2C433" alt="" data-recalc-dims="1"/><figcaption id="caption-attachment-799459">俄罗斯国防部今年8月发布的一张快照显示，一架俄罗斯无人机瞄准了一辆乌克兰装甲车 (法国媒体)</figcaption></figure>
<p>另一方面，自主武器的形式将根据当前冲突的需要和要求来确定，这意味着自主武器的实际使用和类型可能会根据冲突的性质和情况而有所不同。例如，在乌克兰和俄罗斯之间的战争中，莫斯科和基辅使用小型无人机瞄准个人和攻击车辆，而他们则使用较大的中空无人机深入敌后（即最具战略意义和最重要的地区）以瞄准雷达和设施，而乌克兰还使用无人机艇攻击黑海的俄罗斯舰队。</p>
<p>值得注意的是，所有这些无人机都设计为远程控制，都可以升级为自主无人机，这将使它们在通信链路出现故障时能够继续运行。</p>
<p>其他冲突可能会导致不同自主武器的发展，因为包括中国、法国、印度、俄罗斯、英国和美国在内的多个国家正在致力于制造隐形战斗无人机，因此未来的战争可以证明无人机在没有人为干预的情况下瞄准防空系统或移动导弹发射器的自主能力和独立决策。与空中和海上机器人相比，陆地机器人已经远远落后于同行。</p>
<p>然而，未来的战争可能会改变这些机器人的命运，并利用它们安装自主武器并在不需要人类指导的情况下执行军事行动。</p>
<p>这些变化可能不会就此停止，因为成群的无人机可以自我协调其行为，以甚至超过人类能力的速度对战场上的变化做出反应。机器所采取的快速反应也可以导致行动节奏的加快，从而加快战斗的节奏，这反过来又可能会导致将人类排除在决策周期之外的压力增加。</p>
<p>所有这一切的结果将是向一个充满战争的时代转变，这个时代正在寻找一种由机器领导的新形式，它将继续漫无目的地袭击地球，对冲突的本质留下深远的影响。</p>
<figure id="attachment_799467" aria-describedby="caption-attachment-799467"><a href="https://youtu.be/ElyE36WbezQ"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2024/09/maxresdefault-1726569003.jpg?w=770&amp;resize=770%2C433" alt="" data-recalc-dims="1"/></a><figcaption id="caption-attachment-799467"><a href="https://youtu.be/ElyE36WbezQ">“大规模暗杀工厂”：以色列依靠人工智能杀害加沙平民</a></figcaption></figure>
<h3>危险迫在眉睫</h3>
<p>在同一背景下，包括加州大学教授斯图尔特·拉塞尔和图灵奖（通常被称为计算机界的诺贝尔奖*）获得者、法国计算机科学家杨立昆在内的多位领先人工智能科学家发出了关于自主武器的危险的警告。由国际特赦组织、人权观察组织和诺贝尔妇女倡议组织等250多个非政府组织组成的联盟也发起了一场阻止杀手机器人的运动，要求事先达成具有法律约束力的协议来禁止自主武器。</p>
<p>这种不懈追求背后的动机是出于对自主武器可能增加平民伤亡人数的担忧。尽管这些武器能够巧妙而准确地瞄准战斗机，从而减少平民伤亡，但事情并非如此，尤其是如果此类武器落入一个不太关心平民受害者、或者一心想对平民实施集体惩罚的国家手中，那么当然会利用这样的机会犯下最可怕的罪行，例如同时瞄准并杀死数千人，以至于如果我们将这些自主武器与今天的智能炸弹进行比较，后者会显得笨拙无能。（这就是以色列占领军对加沙手无寸铁的平民发动的战争中所发生的情况，事实上人工智能系统的干预执行的任务导致了数千名平民的殉难*）。</p>
<p>我们常常没有意识到人工智能和自主技术的最大危险是它与核武器的结合。2022年，美国宣布将确保人为因素控制使用核武器的决定，而虽然英国采取了类似的政策，但俄罗斯和中国拒绝了这一政策。</p>
<p>尽管人类控制核武器似乎是达成国际协议的一个简单而合乎逻辑的起点，但莫斯科已经表现出了将机器人控制或自动化纳入其核行动的令人担忧的意愿，这并不是什么新鲜事。冷战结束后，苏联前官员解释称，苏联已经建立了半自动报复性核系统，一旦启动，一系列自动传感器将能够检测到对苏联领土的任何核攻击。</p>
<p>如果俄罗斯领土遭受核攻击，而该国主要领导人可能会在袭击中丧生，而该国主要领导人没有做出回应，那么发射核武器的权力将自动转移给位于安全掩体内的相对较低级别的官员。2018年，俄罗斯当局确认该系统仍在运行，甚至已经更新。</p>
<p>最近，莫斯科开始开发配备核武器的自主潜艇，但由于可能发生事故或核武器失去控制，各国派遣核无人机在海上或空中进行巡逻的想法仍然是一个危险的想法。</p>
<figure id="attachment_799456" aria-describedby="caption-attachment-799456"><a href="https://youtu.be/qr2pjRgRkF8"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2024/09/maxresdefault-1-1726568980.jpg?w=770&amp;resize=770%2C433" alt="" data-recalc-dims="1"/></a><figcaption id="caption-attachment-799456"><a href="https://youtu.be/qr2pjRgRkF8">能够消灭整个城市：俄罗斯海军接收“末日潜艇”</a></figcaption></figure>
<p>另一方面，我们会发现自主武器的广泛使用及其与先进军事技术其他方面的融合可能会导致机器主导战争的新时代，因为军事人工智能应用可以加快信息处理和决策的速度。</p>
<p>随着各国采用人工智能和自动化，发现、识别和瞄准敌方目标所需的时间将会减少。从理论上讲，这可能会让人类有更多时间做出明智而谨慎的决策，但在实践中，竞争对手会感到压力，需要做出同样的回应，利用自动化来加快自己的流程，以跟上这种快速的步伐，这最终将导致自动化程度的提高和人为控制的减少的螺旋式上升。</p>
<p>因此，这场竞争的结局很可能是战争的爆发，而战争将以超出人类控制的疯狂速度进行。例如，在金融领域，我们会发现算法在高频交易中的广泛使用（即使用先进的计算机和软件以极快的速度*执行金融交易）导致自动化股票交易的速度超出了人类的能力。</p>
<p>在同一背景下，中国军事研究员陈航辉假设战场上存在“奇点”，他将其定义为机器驱动的战争速度将超过人类决策速度的点。这一奇点将迫使人类在制定战术和战略决策时将判断力让给机器。机器的作用将不仅仅局限于选择特定目标，而是在没有人类干预的情况下规划和实施整个军事行动，而人类的作用将仅限于操作机器和坐在场边，几乎没有控制能力战争，甚至结束战争。</p>
<h3>被困在深渊边缘</h3>
<p>如果努力精心制定这些协议并成功实施，国际组织可以控制自主武器的使用并减轻其造成的一些最严重的伤害。约30个国家和人道主义组织财团呼吁制定禁止自主武器的法律条约。</p>
<p>尽管各国政府在禁止化学和生物武器、集束炸弹以及利用环境作为武器（通过摧毁或污染环境*）方面取得了相对成功，但在监管自主武器方面取得的类似进展已被证明是复杂且难以实现的。由于自主武器尚未完全开发出来，而且我们还没有探索与其军事价值相关的未知或隐藏秘密，因此也不可能实施全面禁令，这使得各国政府对于放弃如此宝贵的武器犹豫不决，因为对其未来潜在危害的未经证实的担忧。</p>
<p>在国际层面，各国政府自2014年起开始在《联合国特定常规武器公约》中讨论如何监管自主武器的相关问题。该公约是一个监管对战斗人员或平民造成严重伤害的武器（例如地雷和致盲激光）的国际论坛。该协议包括126个国家，需要所有参与国政府的支持，这可能会导致达成协议变得困难，或者在监管自主武器等问题上的努力陷入困境。</p>
<p>最近的例子是俄罗斯和美国强烈反对禁止这些武器的条约，并认为战争法中的现有规则足以应对任何潜在的损害。显然，莫斯科和华盛顿的反对对于实现预期目标的努力失败至关重要，如果不包括世界上最大的军事大国，那么对自主武器的禁令就毫无意义。</p>
<p>认识到自2023年以来该问题缺乏进展，自主武器禁令的支持者已将该问题提交联合国大会。大会第一委员会于2023年11月投票委托联合国秘书长编写一份关于自主武器的报告，该禁令的支持者希望该报告将成为获得条约谈判拨款的第一步，而美国则提议全面禁令的替代方法。</p>
<p>2023年末，华盛顿领导40个国家支持一项鼓励负责任地使用军事人工智能的政治宣言。到2024年2月，已有50多个政府加入了这些努力。尽管该声明并未禁止自主武器，但它仍然为其使用提供了一般指导，例如确保进行充分的测试以降低事故风险。这样的声明似乎包含了有价值的原则，但它缺乏对针对平民的自主武器和核行动中的自主武器的道德约束。</p>
<figure id="attachment_799461" aria-describedby="caption-attachment-799461"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2024/09/drone165-1717091310-1726568990.jpg?w=770&amp;resize=770%2C513" alt="" data-recalc-dims="1"/><figcaption id="caption-attachment-799461">自主武器代表了对人类应对武器化人工智能能力的早期考验，随后将出现更凶猛和危险的形式 (路透)</figcaption></figure>
<h3>在为时已晚之前</h3>
<p>如果我们仔细思考事情的发展方向，而不是这些摇摇欲坠的做法或方法，我们会发现这样一个事实：各国可以采取五项举措来减少自主武器构成的威胁。例如，政府可以采用一项一般原则，宣布人类至少最低程度地参与有关生死的关键决策，或者也可以将这一原则采纳为法律规则或具有约束力的政治宣言。</p>
<p>这样的标准需要人类决策者掌握有关预期目标以及攻击的武器、环境和背景的具体且充分的信息，以便在授权之前确定此类攻击的合法性。此外，各国还可以同意，为了使人类监视有意义，任何自主武器的使用都必须在空间、时间和目标上受到限制。尽管这一原则不会禁止所有自主武器（相反，它可能使它们的使用合法化），但另一方面，它将为各国如何使用这些武器提供一个框架，并将确保人类参与有关确认攻击的最关键决策。</p>
<p>其次，政府可以禁止针对人类的自主武器。在一个充满穿制服的战士的世界中（即使是人类也常常发现很难准确地区分平民和士兵），算法将更难推断一个拿着步枪的人是战士还是保护土地的农民。</p>
<p>该机器也不太能够准确识别士兵是真的想投降还是只是假装投降，因此很明显，针对个人的自主武器比仅针对车辆或设备的自主武器带来的风险更大，而且这些武器可能造成的损害远远超过其军事价值。在它的使用变得普遍之前，各国必须选择是否要禁止它。</p>
<p>第三，各国可以建立测试军事人工智能和自主系统的标准和程序，以避免发生事故，美国还应该与其他国家分享提高这些系统安全性的最佳实践，就像在使用或出口各种武器之前分享有关各种武器审查程序的信息一样，但不透露其个别审查的细节。</p>
<p>第四，美国应与英国合作，说服其他拥有核武库的国家有必要达成协议，确保人类对核武器进行严格控制。伦敦是这项努力的合适合作伙伴，因为它的政策是维持人类对其核武库的控制。</p>
<p>因此，获得其他核国家的类似声明以维持人类对核武库的控制将是确保最强大的武器仍然处于人类控制之下的重要一步。联合国安理会五个常任理事国（俄罗斯、中国、法国、英国和美国*）之间达成协议将代表一份强有力的官方声明，反映这些国家对人类控制核武器的承诺。与此同时，美国必须在两国新的人工智能双边会谈中就此问题向北京施压。</p>
<p>第五，也是最后一点，随着各国越来越多地在空中和海上使用无人机，各国可以采取统一的规则来控制无人机，以减少事故，并且随着这些飞机的独立性增加，发生事故或判断错误而导致国际事件的可能性也会增加。例如，2019年，伊朗防空系统在霍尔木兹海峡击落了一架美国“全球鹰”无人机。2023年3月，一架俄罗斯战斗机在黑海上空拦截了一架美国MQ-9“死神”无人机，导致这架美国无人机最终坠毁。</p>
<p>由于这些飞机被设计为远程控制，因此假设人类决定如何应对。但在未来，空中和海上飞机可能会实现自主，这意味着在发生类似事故时，这些飞机将自动执行其上编程的程序，如果它们被编程为立即响应，这可能会导致国际局势升级，而无需任何人为决定这样做。因此，各国政府必须确保自主武器所能采取的任何行为都必须符合人类的意图。</p>
<p>1972年美国和苏联之间的海上事故协议有助于减少冷战期间美苏海军之间随机事故的数量（该协议规定双方就涉及军舰海上事故的调查建立合作与协调机制*）。</p>
<p>针对自主武器引起的事件制定类似的公约也可能有助于各国应对在争议地区部署的竞争性自主系统的风险，并避免意外和不必要的事件。因此，作为当今世界上最大的军事、经济和技术大国，美国和中国之间的协议被认为是管理自主武器风险的艰难但决定性的一步。</p>
<p>最终，重要的是要认识到，无论我们喜欢与否，自主武器正在出现和传播，并且试图完全禁止它们 – 尽管意图最好 – 可能是徒劳的和徒劳的，这是因为它们的军事价值实在是太大了。然而，各国可以选择通过在这个问题上采取紧急措施，以增强稳定的方式调整这些武器，这将需要超越目前的选择，这似乎很简单，但同时具有误导性，并且有两种可能性：要么禁止所有自主武器，要么根本不对其施加限制。</p>
<p>在这把丰富的死亡之伞下，自主武器代表了对人类应对武器化人工智能能力的早期考验，随后将出现更凶猛和危险的形式。事实上，现代人工智能系统已经证明了其帮助开发网络、化学和生物武器的能力，因此世界迫切需要达成一项国际协议，控制其发展，限制其蔓延，应对其负面影响，为未来合作应对其危险奠定基础。</p>
